# 🏗️ 异步RAG系统架构

## 📊 系统架构对比

### 原有同步架构

```
┌─────────────┐
│   用户A     │ ──┐
└─────────────┘   │
                  │
┌─────────────┐   │    ┌──────────────┐    ┌──────────────┐
│   用户B     │ ──┼───>│  API服务     │───>│  RAG系统     │
└─────────────┘   │    │  (阻塞等待)  │    │  (AI模型)    │
                  │    └──────────────┘    └──────────────┘
┌─────────────┐   │           ↑                    ↓
│   用户C     │ ──┘           └────────────────────┘
└─────────────┘              等待15秒后返回

问题：
❌ 用户A处理时，B和C必须等待
❌ 10个用户 = 150秒总耗时
❌ API进程被长时间占用
```

---

### 新异步架构

```
┌─────────────┐
│   用户A     │ ──┐  0.1秒返回task_id
└─────────────┘   │
                  │
┌─────────────┐   │    ┌──────────────┐    ┌──────────────┐
│   用户B     │ ──┼───>│  API服务     │───>│    Redis     │
└─────────────┘   │    │  (立即返回)  │    │    队列      │
                  │    └──────────────┘    └──────────────┘
┌─────────────┐   │                              │
│   用户C     │ ──┘                              │
└─────────────┘                                  ▼
                                        ┌──────────────┐
      ┌─────────────────────────────────│  Worker 1    │
      │                                 └──────────────┘
      │                                          │
      │                                 ┌──────────────┐
      │                                 │  Worker 2    │
      │                                 └──────────────┘
      │                                          │
      │                                 ┌──────────────┐
      │                                 │  Worker 3    │
      │                                 └──────────────┘
      │                                          │
      │                                          ▼
      │                                 ┌──────────────┐
      │                                 │  RAG系统     │
      │                                 │  (AI模型)    │
      │                                 └──────────────┘
      │                                          │
      └──────────── 轮询查询结果 ←───────────────┘

优势：
✅ 所有用户立即得到响应
✅ 10个用户 = 30秒总耗时（3个Worker并行）0
✅ API进程不被阻塞
```

---

## 🔄 请求处理流程

### 同步模式流程

```
时间轴 (秒)
0  ────> 用户A发起请求
         │
         ├─> API接收请求
         │
         ├─> 调用AI模型
         │   (阻塞中...)
         │
15 ────> 返回结果给用户A
         │
         ├─> 用户B发起请求
         │
         ├─> API接收请求
         │
         ├─> 调用AI模型
         │   (阻塞中...)
         │
30 ────> 返回结果给用户B

总耗时: 30秒 (串行处理)
```

---

### 异步模式流程

```
时间轴 (秒)
0  ────> 用户A发起请求
         ├─> API立即返回task_id_A (0.1秒)
         └─> 任务进入Redis队列
         
0.1 ───> 用户B发起请求
         ├─> API立即返回task_id_B (0.1秒)
         └─> 任务进入Redis队列
         
0.2 ───> 用户C发起请求
         ├─> API立即返回task_id_C (0.1秒)
         └─> 任务进入Redis队列

         ┌─────────────────────────────┐
         │  Worker并行处理（后台）     │
         ├─────────────────────────────┤
         │ Worker1: 处理task_A (15秒) │
         │ Worker2: 处理task_B (15秒) │
         │ Worker3: 处理task_C (15秒) │
         └─────────────────────────────┘

15 ────> 所有任务完成

总耗时: 15秒 (并行处理)
用户等待: 0.1秒 + 轮询
```

---

## 🎯 核心组件详解

### 1. API服务 (api_async.py)

**职责**:
- 接收用户请求
- 提交任务到Redis队列
- 立即返回task_id
- 提供任务状态查询接口

**关键接口**:
```python
POST /api/async/analyze-image    # 提交图片分析任务
POST /api/async/complete-answer  # 提交答案生成任务
POST /api/async/query             # 提交完整查询任务
GET  /api/async/task/{task_id}    # 查询任务状态
GET  /api/queue/stats             # 查看队列统计
```

**特点**:
- ✅ 非阻塞
- ✅ 高并发
- ✅ 轻量级

---

### 2. Redis队列

**职责**:
- 存储待处理任务
- 管理任务状态
- 保存任务结果

**队列类型**:
```
image_analysis      # 图片分析队列（优先级高）
answer_generation   # 答案生成队列（优先级中）
full_query          # 完整查询队列（优先级低）
```

**任务状态**:
```
queued   → 已提交，等待处理
started  → 正在处理
finished → 处理完成
failed   → 处理失败
```

---

### 3. Worker进程 (start_worker.py)

**职责**:
- 从Redis队列获取任务
- 调用RAG系统处理任务
- 将结果写回Redis

**工作流程**:
```
1. 连接Redis
2. 监听队列
3. 获取任务
4. 执行任务
5. 保存结果
6. 返回步骤2
```

**扩展性**:
- 可启动多个Worker
- 自动负载均衡
- 失败自动重试

---

### 4. 任务处理器 (image_tasks.py)

**职责**:
- 定义具体的任务逻辑
- 调用RAG系统
- 处理异常

**任务类型**:
```python
analyze_image_task()      # 图片分析
complete_answer_task()    # 答案生成
full_query_task()         # 完整查询
```

---

## 📈 性能分析

### 并发处理能力

#### 1个Worker

```
时间: 0s ──────> 15s ──────> 30s ──────> 45s
任务: [Task1] → [Task2] → [Task3]

吞吐量: 4 任务/分钟
```

#### 3个Worker

```
时间: 0s ──────────────────> 15s
任务: [Task1]
      [Task2]  (并行处理)
      [Task3]

吞吐量: 12 任务/分钟
```

#### 5个Worker

```
时间: 0s ──────────────────> 15s
任务: [Task1]
      [Task2]
      [Task3]  (并行处理)
      [Task4]
      [Task5]

吞吐量: 20 任务/分钟
```

---

### 响应时间对比

| 并发用户 | 同步模式 | 异步模式(1 Worker) | 异步模式(3 Workers) |
|---------|---------|-------------------|-------------------|
| 1       | 15秒    | 15秒              | 15秒              |
| 3       | 45秒    | 45秒              | 15秒              |
| 5       | 75秒    | 75秒              | 25秒              |
| 10      | 150秒   | 150秒             | 50秒              |

**结论**: Worker数量 = 并发处理能力

---

## 🔧 扩展方案

### 方案1: 垂直扩展（增加Worker）

```bash
# 启动5个Worker
for i in {1..5}; do
    nohup python start_worker.py > logs/worker_$i.log 2>&1 &
done
```

**效果**:
- 并发能力: 5倍
- 成本: 低（同一台机器）
- 限制: 受机器资源限制

---

### 方案2: 水平扩展（多台机器）

```
┌──────────────┐
│  机器1       │
│  - API服务   │
│  - Redis     │
└──────────────┘
       │
       ├─────> ┌──────────────┐
       │       │  机器2       │
       │       │  - Worker x3 │
       │       └──────────────┘
       │
       └─────> ┌──────────────┐
               │  机器3       │
               │  - Worker x3 │
               └──────────────┘
```

**效果**:
- 并发能力: 无限扩展
- 成本: 高
- 限制: 无

---

### 方案3: 混合扩展（推荐）

```
┌──────────────┐
│  负载均衡    │
│  (Nginx)     │
└──────────────┘
       │
       ├─────> ┌──────────────┐
       │       │  API服务1    │
       │       └──────────────┘
       │
       └─────> ┌──────────────┐
               │  API服务2    │
               └──────────────┘
                      │
                      ▼
              ┌──────────────┐
              │    Redis     │
              │   (集群)     │
              └──────────────┘
                      │
       ┌──────────────┼──────────────┐
       │              │              │
       ▼              ▼              ▼
┌──────────┐   ┌──────────┐   ┌──────────┐
│ Worker x3│   │ Worker x3│   │ Worker x3│
└──────────┘   └──────────┘   └──────────┘
```

**效果**:
- 高可用
- 高性能
- 易扩展

---

## 🎯 最佳实践

### 1. Worker数量配置

```python
# 经验公式
Worker数量 = CPU核心数 × 2

# 示例
4核CPU → 8个Worker
8核CPU → 16个Worker
```

### 2. 队列优先级

```python
# 高优先级: 图片分析（用户直接交互）
image_analysis_queue

# 中优先级: 答案生成（依赖图片分析）
answer_generation_queue

# 低优先级: 完整查询（批量处理）
full_query_queue
```

### 3. 超时设置

```python
# 图片分析: 10分钟
job_timeout='10m'

# 完整查询: 15分钟
job_timeout='15m'

# 结果保留: 1小时
result_ttl=3600
```

### 4. 监控指标

```python
# 关键指标
- 队列长度 (queued)
- 处理中任务 (started)
- 完成任务数 (finished)
- 失败任务数 (failed)
- 平均处理时间
- Worker利用率
```

---

## 🔍 故障处理

### 场景1: Redis宕机

**影响**: 
- 无法提交新任务
- 正在处理的任务不受影响

**恢复**:
```bash
# 重启Redis
redis-server --daemonize yes

# 检查数据
redis-cli
> KEYS *
```

---

### 场景2: Worker崩溃

**影响**:
- 该Worker的任务会重新入队
- 其他Worker继续工作

**恢复**:
```bash
# 重启Worker
python start_worker.py
```

---

### 场景3: API服务宕机

**影响**:
- 无法提交新任务
- Worker继续处理已有任务

**恢复**:
```bash
# 重启API
python api_async.py
```

---

## 📊 监控面板

### RQ Dashboard (可选)

```bash
# 安装
pip install rq-dashboard

# 启动
rq-dashboard --redis-url redis://localhost:6379

# 访问
http://localhost:9181
```

**功能**:
- 实时查看队列状态
- 查看Worker列表
- 查看任务详情
- 手动重试失败任务

---

## 🎉 总结

### 核心优势

1. **高性能**: 并发处理，吞吐量提升5倍
2. **可扩展**: 增加Worker即可提升性能
3. **高可用**: 组件独立，单点故障不影响整体
4. **易维护**: 清晰的架构，便于调试和监控

### 适用场景

- ✅ 生产环境
- ✅ 高并发需求
- ✅ 长时间任务
- ✅ 需要进度反馈
- ✅ 需要任务管理

### 技术栈

- **API**: FastAPI
- **队列**: Redis + RQ
- **任务**: Python异步任务
- **监控**: RQ Dashboard (可选)
